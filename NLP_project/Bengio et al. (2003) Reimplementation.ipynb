{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project: Reimplementation of \n",
    "## A Neural Probabilistic Language Model \n",
    "### *(Bengio et al., 2003)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created by Dennis Linnert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: To enable training of the neural network, I executed this juypter notebook using the GPU resources provided by Kaggle's online platform (https://www.kaggle.com/code) to utilize CUDA instead of running the training on my old laptop cpu.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:25.397519Z",
     "iopub.status.busy": "2024-06-27T19:52:25.396992Z",
     "iopub.status.idle": "2024-06-27T19:52:34.333292Z",
     "shell.execute_reply": "2024-06-27T19:52:34.332247Z",
     "shell.execute_reply.started": "2024-06-27T19:52:25.397472Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:34.335389Z",
     "iopub.status.busy": "2024-06-27T19:52:34.334983Z",
     "iopub.status.idle": "2024-06-27T19:52:38.673906Z",
     "shell.execute_reply": "2024-06-27T19:52:38.672722Z",
     "shell.execute_reply.started": "2024-06-27T19:52:34.335361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the Brown corpus: 1161192\n"
     ]
    }
   ],
   "source": [
    "# Download & load the Brown corpus (utilized in the paper)\n",
    "#nltk.download('brown') #commented out due to warning message when corpus is already downloaded\n",
    "corpus = brown.words()\n",
    "\n",
    "# Find total number of words in the corpus\n",
    "total_words = len(corpus)\n",
    "print(f\"Total words in the Brown corpus: {total_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:38.676190Z",
     "iopub.status.busy": "2024-06-27T19:52:38.675751Z",
     "iopub.status.idle": "2024-06-27T19:52:42.845745Z",
     "shell.execute_reply": "2024-06-27T19:52:42.844724Z",
     "shell.execute_reply.started": "2024-06-27T19:52:38.676154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16690\n"
     ]
    }
   ],
   "source": [
    "# Convert all words to lowercase\n",
    "corpus = [word.lower() for word in corpus]\n",
    "\n",
    "# Replace rare words with a single symbol like Bengio et al. (all words with frequency equal or lower than 3)\n",
    "word_freq = Counter(corpus)\n",
    "vocab = {word for word, freq in word_freq.items() if freq > 3}\n",
    "vocab.add('<UNK>')\n",
    "\n",
    "# Create word to index and index to word mappings\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "word_to_idx['<UNK>'] = len(word_to_idx) - 1\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Ensure all words are within the vocabulary range\n",
    "corpus_indices = [word_to_idx.get(word, word_to_idx['<UNK>']) for word in corpus]\n",
    "\n",
    "# Check the Vocabulary Size\n",
    "vocab_size = len(word_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "In the paper, the Brown corpus utilized was slightly larger (1 181 041 words). Therefore to stick as close to the paper as possible, I will calculate the proportions from the numbers used in the paper (originally 800 000 words were used for training, 200 000 validation, rest of 181 041 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:42.849437Z",
     "iopub.status.busy": "2024-06-27T19:52:42.848822Z",
     "iopub.status.idle": "2024-06-27T19:52:42.864274Z",
     "shell.execute_reply": "2024-06-27T19:52:42.863096Z",
     "shell.execute_reply.started": "2024-06-27T19:52:42.849401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 786554, Validation size: 196638, Test size: 178000\n"
     ]
    }
   ],
   "source": [
    "# Define proportions based on the original paper (See note above)\n",
    "train_proportion = 800000 / 1181041\n",
    "valid_proportion = 200000 / 1181041\n",
    "test_proportion = 181041 / 1181041\n",
    "\n",
    "# Calculate actual sizes based on proportions\n",
    "train_size = int(train_proportion * total_words)\n",
    "valid_size = int(valid_proportion * total_words)\n",
    "test_size = total_words - train_size - valid_size\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data = corpus_indices[:train_size]\n",
    "valid_data = corpus_indices[train_size:train_size + valid_size]\n",
    "test_data = corpus_indices[train_size + valid_size:]\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(valid_data)}, Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters from the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:42.866469Z",
     "iopub.status.busy": "2024-06-27T19:52:42.866120Z",
     "iopub.status.idle": "2024-06-27T19:52:42.880735Z",
     "shell.execute_reply": "2024-06-27T19:52:42.880012Z",
     "shell.execute_reply.started": "2024-06-27T19:52:42.866436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters from the paper\n",
    "context_size = 5  # as used in the papers best approach (n = 5)\n",
    "embedding_dim = 30 #  m = 30 \n",
    "hidden_dim = 100 # h = 100\n",
    "epochs = 15 # On the brown corpus they used 10 to 20 epochs\n",
    "learning_rate = 0.001 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Probabilistic Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:42.882057Z",
     "iopub.status.busy": "2024-06-27T19:52:42.881793Z",
     "iopub.status.idle": "2024-06-27T19:52:42.961270Z",
     "shell.execute_reply": "2024-06-27T19:52:42.960358Z",
     "shell.execute_reply.started": "2024-06-27T19:52:42.882034Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralProbabilisticLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_dim):\n",
    "        super(NeuralProbabilisticLanguageModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # Embedding layer (distributed word representations as vector)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_dim) # First linear layer\n",
    "        self.linear2 = nn.Linear(hidden_dim, vocab_size) # Second linear layer\n",
    "\n",
    "    def forward(self, inputs):\n",
    "         # Forward pass: get embeddings, reshape, apply linear transformations and activations\n",
    "        embeds = self.embeddings(inputs).view((inputs.shape[0], -1)) # flat vector that represents word contexts\n",
    "        hidden = torch.tanh(self.linear1(embeds))  # Applying tanh activation fucntion\n",
    "        output = self.linear2(hidden)  # Linear transformation\n",
    "        log_probs = F.log_softmax(output, dim=1)  # Softmax to get log probabilities\n",
    "        return log_probs\n",
    "\n",
    "# Initalise the model\n",
    "model = NeuralProbabilisticLanguageModel(vocab_size, embedding_dim, context_size, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "#### as described in the paper, Negative Log-Likelihood. \n",
    "\n",
    "A more detailed description of the perplexity formula and calculation is displayed below in the chapter after the training function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:42.962938Z",
     "iopub.status.busy": "2024-06-27T19:52:42.962626Z",
     "iopub.status.idle": "2024-06-27T19:52:45.075841Z",
     "shell.execute_reply": "2024-06-27T19:52:45.074926Z",
     "shell.execute_reply.started": "2024-06-27T19:52:42.962913Z"
    }
   },
   "outputs": [],
   "source": [
    "def negative_log_likelihood_loss(log_probs, target):\n",
    "    return -log_probs[range(target.size(0)), target].mean()\n",
    "\n",
    "# Define optimizer with weight decay as specified in the paper \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset Class for Brown Corpus, Create Dataloader and Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T19:52:45.077683Z",
     "iopub.status.busy": "2024-06-27T19:52:45.077197Z",
     "iopub.status.idle": "2024-06-27T20:01:19.362819Z",
     "shell.execute_reply": "2024-06-27T20:01:19.361624Z",
     "shell.execute_reply.started": "2024-06-27T19:52:45.077633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Loss: 9.330602554890856\n",
      "Epoch 2, Loss: 8.07758345181036\n",
      "Epoch 3, Loss: 7.542020863415848\n",
      "Epoch 4, Loss: 7.243356521814407\n",
      "Epoch 5, Loss: 7.0721296347671645\n",
      "Epoch 6, Loss: 6.960651938754237\n",
      "Epoch 7, Loss: 6.881320454688263\n",
      "Epoch 8, Loss: 6.821043903755889\n",
      "Epoch 9, Loss: 6.77289244183881\n",
      "Epoch 10, Loss: 6.7329027452926695\n",
      "Epoch 11, Loss: 6.698673285576655\n",
      "Epoch 12, Loss: 6.668700559591258\n",
      "Epoch 13, Loss: 6.642030216136339\n",
      "Epoch 14, Loss: 6.61803004603933\n",
      "Epoch 15, Loss: 6.596240571497707\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset class for the Brown corpus\n",
    "class BrownDataset(Dataset):\n",
    "    def __init__(self, data, context_size):\n",
    "        self.data = data\n",
    "        self.context_size = context_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.context_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return context and target for the current index\n",
    "        return (torch.tensor(self.data[idx:idx + self.context_size], dtype=torch.long),\n",
    "                torch.tensor(self.data[idx + self.context_size], dtype=torch.long))\n",
    "\n",
    "# Create Dataloader for training data \n",
    "batch_size = 64\n",
    "train_dataset = BrownDataset(train_data, context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Training Function\n",
    "def train(model, train_loader, loss_function, optimizer, epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []  # List to store the loss for each epoch\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (context, target) in enumerate(train_loader):\n",
    "            context, target = context.to(device), target.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            log_probs = model(context)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(log_probs, target)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum up loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)  # Average loss for the epoch\n",
    "        epoch_losses.append(average_loss)  # Store the average loss\n",
    "        print(f'Epoch {epoch + 1}, Loss: {average_loss}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, negative_log_likelihood_loss, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Calculation\n",
    "\n",
    "As explained in the paper, the perplexity of a language model is calculated using the following formula (also see loss calculation above):\n",
    "\n",
    "$$\n",
    "\\text{Perplexity} = \\exp\\left( -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i \\mid w_{1:i-1}) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of words.\n",
    "- $P(w_i \\mid w_{1:i-1})$ is the probability of the $i$-th word given its previous context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:01:19.364447Z",
     "iopub.status.busy": "2024-06-27T20:01:19.364117Z",
     "iopub.status.idle": "2024-06-27T20:01:22.978787Z",
     "shell.execute_reply": "2024-06-27T20:01:22.977695Z",
     "shell.execute_reply.started": "2024-06-27T20:01:19.364420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Perplexity: 764.3944241504812\n",
      "Test Perplexity: 718.8795194481878\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(data, model, context_size, batch_size):\n",
    "    model.eval() \n",
    "    data_len = len(data) - context_size\n",
    "    perplexity_sum = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_len, batch_size):\n",
    "            context_batch = []\n",
    "            target_batch = []\n",
    "            for j in range(i, min(i + batch_size, data_len)):\n",
    "                context_batch.append(data[j:j + context_size])\n",
    "                target_batch.append(data[j + context_size])\n",
    "\n",
    "            context_batch = torch.tensor(context_batch, dtype=torch.long).to(device)\n",
    "            target_batch = torch.tensor(target_batch, dtype=torch.long).to(device)\n",
    "\n",
    "            log_probs = model(context_batch)\n",
    "            loss = negative_log_likelihood_loss(log_probs, target_batch)\n",
    "\n",
    "            perplexity_sum += torch.exp(loss).item()\n",
    "            num_batches += 1\n",
    "\n",
    "    return perplexity_sum / num_batches\n",
    "\n",
    "# Calculate perplexity on validation and test sets\n",
    "validation_perplexity = calculate_perplexity(valid_data, model, context_size, batch_size)\n",
    "test_perplexity = calculate_perplexity(test_data, model, context_size, batch_size)\n",
    "\n",
    "print(f'Validation Perplexity: {validation_perplexity}')\n",
    "print(f'Test Perplexity: {test_perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create interpolated trigram model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:01:22.982309Z",
     "iopub.status.busy": "2024-06-27T20:01:22.981988Z",
     "iopub.status.idle": "2024-06-27T20:01:26.242538Z",
     "shell.execute_reply": "2024-06-27T20:01:26.241641Z",
     "shell.execute_reply.started": "2024-06-27T20:01:22.982280Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpolatedTrigramModel:\n",
    "    def __init__(self, corpus):\n",
    "        self.trigrams = defaultdict(Counter)\n",
    "        self.bigrams = defaultdict(Counter)\n",
    "        self.unigrams = Counter()\n",
    "        self.total_words = 0\n",
    "        self.train(corpus)\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # First train the trigram, bigram and unigram counts for interpolated trigram model\n",
    "        for i in range(2, len(corpus)):\n",
    "            trigram = (corpus[i-2], corpus[i-1], corpus[i])\n",
    "            bigram = (corpus[i-2], corpus[i-1])\n",
    "            unigram = corpus[i-2]\n",
    "\n",
    "            self.trigrams[bigram][corpus[i]] += 1\n",
    "            self.bigrams[bigram[0]][bigram[1]] += 1\n",
    "            self.unigrams[unigram] += 1\n",
    "            self.total_words += 1\n",
    "\n",
    "    def trigram_probability(self, word, context):\n",
    "        bigram = context\n",
    "        epsilon = 1e-10  # Small value to avoid zero probabilities\n",
    "        if self.trigrams[bigram][word] > 0:\n",
    "            return self.trigrams[bigram][word] / sum(self.trigrams[bigram].values())\n",
    "        elif self.bigrams[bigram[0]][bigram[1]] > 0:\n",
    "            return 0.4 * (self.bigrams[bigram[0]][bigram[1]] / sum(self.bigrams[bigram[0]].values()))\n",
    "        else:\n",
    "            return 0.1 * (self.unigrams[word] / self.total_words + epsilon)\n",
    "\n",
    "# Train the interpolated trigram model\n",
    "trigram_model = InterpolatedTrigramModel(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:01:26.243923Z",
     "iopub.status.busy": "2024-06-27T20:01:26.243634Z",
     "iopub.status.idle": "2024-06-27T20:01:31.780336Z",
     "shell.execute_reply": "2024-06-27T20:01:31.779263Z",
     "shell.execute_reply.started": "2024-06-27T20:01:26.243897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Trigram Validation Perplexity: 291.5492151600732\n",
      "Interpolated Trigram Test Perplexity: 277.4435776519447\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the interpolated trigram model on the validation set\n",
    "def evaluate_trigram_model(trigram_model, data, context_size):\n",
    "    log_prob_sum = 0\n",
    "    epsilon = 1e-10  # Small value to avoid log(0)\n",
    "    for i in range(context_size, len(data)):\n",
    "        context = tuple(data[i-context_size:i])\n",
    "        target = data[i]\n",
    "        prob = trigram_model.trigram_probability(target, context[-2:])\n",
    "        log_prob_sum += -math.log(prob + epsilon)\n",
    "    perplexity = math.exp(log_prob_sum / (len(data) - context_size))\n",
    "    return perplexity\n",
    "\n",
    "# Calculate perplexity on validation and test data\n",
    "trigram_validation_perplexity = evaluate_trigram_model(trigram_model, valid_data, context_size)\n",
    "trigram_test_perplexity = evaluate_trigram_model(trigram_model, test_data, context_size)\n",
    "\n",
    "print(f'Interpolated Trigram Validation Perplexity: {trigram_validation_perplexity}')\n",
    "print(f'Interpolated Trigram Test Perplexity: {trigram_test_perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model\n",
    "\n",
    "In the Paper, a mixture model (neural model/trigram) had the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:01:31.781986Z",
     "iopub.status.busy": "2024-06-27T20:01:31.781642Z",
     "iopub.status.idle": "2024-06-27T20:01:31.788743Z",
     "shell.execute_reply": "2024-06-27T20:01:31.787561Z",
     "shell.execute_reply.started": "2024-06-27T20:01:31.781958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mixture function to combine neural and interpol. trigram model with a simple fixed weight of 0.5\n",
    "def mixture_model_probability(context, word, model, trigram_model, alpha=0.5):\n",
    "    context_tensor = torch.tensor(context).unsqueeze(0).to(device)\n",
    "    neural_log_probs = model(context_tensor)\n",
    "    neural_prob = torch.exp(neural_log_probs).cpu().detach().numpy()[0][word]\n",
    "    trigram_prob = trigram_model.trigram_probability(word, (context[-2], context[-1]))\n",
    "    return alpha * neural_prob + (1 - alpha) * trigram_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:01:31.790614Z",
     "iopub.status.busy": "2024-06-27T20:01:31.790213Z",
     "iopub.status.idle": "2024-06-27T20:04:23.864700Z",
     "shell.execute_reply": "2024-06-27T20:04:23.863272Z",
     "shell.execute_reply.started": "2024-06-27T20:01:31.790579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture Model Validation Perplexity: 182.98508888003227\n",
      "Mixture Model Test Perplexity: 174.8710499575007\n"
     ]
    }
   ],
   "source": [
    "# Calculate perplexity for mixture model\n",
    "def mixture_model_perplexity(data, model, trigram_model, context_size, batch_size, alpha=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    data_len = len(data) - context_size\n",
    "    perplexity_sum = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_len, batch_size):\n",
    "            context_batch = []\n",
    "            target_batch = []\n",
    "            for j in range(i, min(i + batch_size, data_len)):\n",
    "                context_batch.append(data[j:j + context_size])\n",
    "                target_batch.append(data[j + context_size])\n",
    "\n",
    "            context_batch = torch.tensor(context_batch, dtype=torch.long).to(device)\n",
    "            target_batch = torch.tensor(target_batch, dtype=torch.long).to(device)\n",
    "\n",
    "            log_probs = model(context_batch)\n",
    "            neural_probs = torch.exp(log_probs).cpu().detach().numpy()\n",
    "\n",
    "            # Calculate mixture probabilities\n",
    "            mixture_probs = []\n",
    "            for k in range(context_batch.size(0)):\n",
    "                context = context_batch[k].cpu().numpy()\n",
    "                target = target_batch[k].item()\n",
    "                mixture_prob = mixture_model_probability(context, target, model, trigram_model, alpha)\n",
    "                mixture_probs.append(mixture_prob)\n",
    "\n",
    "            mixture_probs = torch.tensor(mixture_probs)\n",
    "            loss = -torch.log(mixture_probs).mean()\n",
    "            perplexity_sum += torch.exp(loss).item()\n",
    "            num_batches += 1\n",
    "\n",
    "    return perplexity_sum / num_batches\n",
    "\n",
    "mixture_validation_perplexity = mixture_model_perplexity(valid_data, model, trigram_model, context_size, batch_size)\n",
    "mixture_test_perplexity = mixture_model_perplexity(test_data, model, trigram_model, context_size, batch_size)\n",
    "\n",
    "print(f'Mixture Model Validation Perplexity: {mixture_validation_perplexity}')\n",
    "print(f'Mixture Model Test Perplexity: {mixture_test_perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Perplexity Comparison\n",
    "\n",
    "Comparison of test perplexities for the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:04:23.866717Z",
     "iopub.status.busy": "2024-06-27T20:04:23.866259Z",
     "iopub.status.idle": "2024-06-27T20:04:23.875996Z",
     "shell.execute_reply": "2024-06-27T20:04:23.875012Z",
     "shell.execute_reply.started": "2024-06-27T20:04:23.866658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \n",
       "\\begin{array}{|c|c|c|}\n",
       "\\hline\n",
       "\\text{Model} & \\text{Test Perplexity} & \\text{Bengio et al.} \\\\\n",
       "\\hline\n",
       "\\text{Neural Model} & 719 & 268 \\\\\n",
       "\\hline\n",
       "\\text{Interpolated Trigram Model} & 277 & 312 \\\\\n",
       "\\hline\n",
       "\\text{Mixture Model} & 175 & 252 \\\\\n",
       "\\hline\n",
       "\\end{array}\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latex_table = f\"\"\"\n",
    "\\\\begin{{array}}{{|c|c|c|}}\n",
    "\\\\hline\n",
    "\\\\text{{Model}} & \\\\text{{Test Perplexity}} & \\\\text{{Bengio et al.}} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\text{{Neural Model}} & {round(test_perplexity)} & 268 \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\text{{Interpolated Trigram Model}} & {round(trigram_test_perplexity)} & 312 \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\text{{Mixture Model}} & {round(mixture_test_perplexity)} & 252 \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{{array}}\n",
    "\"\"\"\n",
    "\n",
    "display(Math(latex_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the reimplemented model was mostly able to create similar perplexity scores as observed in the paper, especially the mixed model.\n",
    "\n",
    "Nevertheless, the neural model without mixture unfortunately achieves a significantly higher perplexity, I assume differences in the dataset (as the utilized brown corpus from the nltk library did deviate from the descriptions from the authors) and further specifications of the authors that they did not explicitly mention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "As this paper is over 20 years old, there are new ways to handle the problem (like using a ReLU activation function to mitigate the possible issue of gradient vanishing or using adaptive learning rates like adam). But as the task is to reimplement the paper, I will try to adjust hyperparameters only.  \n",
    "\n",
    "In the following, the best hyperparameter combination of my experiments is displayed, where I changed the learning rate and weight decay along with number of epochs, batch_size, embedding dimension and hidden dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T20:04:23.877614Z",
     "iopub.status.busy": "2024-06-27T20:04:23.877281Z",
     "iopub.status.idle": "2024-06-27T20:19:48.937163Z",
     "shell.execute_reply": "2024-06-27T20:19:48.936243Z",
     "shell.execute_reply.started": "2024-06-27T20:04:23.877588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8.0648157741672\n",
      "Epoch 2, Loss: 6.956512863148007\n",
      "Epoch 3, Loss: 6.69932531092402\n",
      "Epoch 4, Loss: 6.560917732500696\n",
      "Epoch 5, Loss: 6.470315258083225\n",
      "Epoch 6, Loss: 6.404835165652552\n",
      "Epoch 7, Loss: 6.35418316831505\n",
      "Epoch 8, Loss: 6.313470383478693\n",
      "Epoch 9, Loss: 6.279439462654915\n",
      "Epoch 10, Loss: 6.250393284519293\n",
      "Epoch 11, Loss: 6.224869589521642\n",
      "Epoch 12, Loss: 6.2021346186877775\n",
      "Epoch 13, Loss: 6.181478220439678\n",
      "Epoch 14, Loss: 6.1628125923447215\n",
      "Epoch 15, Loss: 6.145415593621167\n",
      "Epoch 16, Loss: 6.129393770451892\n",
      "Epoch 17, Loss: 6.114214642366756\n",
      "Epoch 18, Loss: 6.100332642936023\n",
      "Epoch 19, Loss: 6.086979032610202\n",
      "Epoch 20, Loss: 6.074329304997711\n",
      "Epoch 21, Loss: 6.062488515408854\n",
      "Epoch 22, Loss: 6.051138480323322\n",
      "Epoch 23, Loss: 6.040405781463812\n",
      "Epoch 24, Loss: 6.030129662484871\n",
      "Epoch 25, Loss: 6.0203173027882695\n",
      "Epoch 26, Loss: 6.010881852684679\n",
      "Epoch 27, Loss: 6.001757072618797\n",
      "Epoch 28, Loss: 5.992955295495711\n",
      "Epoch 29, Loss: 5.984464758814952\n",
      "Epoch 30, Loss: 5.976335385083919\n",
      "Epoch 31, Loss: 5.968223965133086\n",
      "Epoch 32, Loss: 5.960487776767769\n",
      "Epoch 33, Loss: 5.953085563565325\n",
      "Epoch 34, Loss: 5.945762591450446\n",
      "Epoch 35, Loss: 5.938444356673166\n",
      "Epoch 36, Loss: 5.93160704995381\n",
      "Epoch 37, Loss: 5.924918449239238\n",
      "Epoch 38, Loss: 5.91815160905892\n",
      "Epoch 39, Loss: 5.9117089224063415\n",
      "Epoch 40, Loss: 5.905315224914104\n",
      "Adjusted Neural Model Test Perplexity: 405.40811869741856\n"
     ]
    }
   ],
   "source": [
    "# Trying different hyperparameters:\n",
    "learning_rate = 0.01\n",
    "epochs = 40\n",
    "batch_size = 256\n",
    "embedding_dim = 100\n",
    "hidden_dim = 200\n",
    "\n",
    "# Redefine the model with adjusted parameters\n",
    "class NeuralProbabilisticLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_dim):\n",
    "        super(NeuralProbabilisticLanguageModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((inputs.shape[0], -1))\n",
    "        hidden = torch.tanh(self.linear1(embeds))\n",
    "        output = self.linear2(hidden)\n",
    "        log_probs = F.log_softmax(output, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "# Reinitialize the model\n",
    "model = NeuralProbabilisticLanguageModel(vocab_size, embedding_dim, context_size, hidden_dim).to(device)\n",
    "\n",
    "# Reinitialize the DataLoader with new batch size\n",
    "train_dataset = BrownDataset(train_data, context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Reinitialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Retrain the model\n",
    "train(model, train_loader, negative_log_likelihood_loss, optimizer, epochs)\n",
    "# Calculate perplexity on test set for the new neural model\n",
    "new_neural_test_perplexity = calculate_perplexity(test_data, model, context_size, batch_size)\n",
    "\n",
    "print(f'Adjusted Neural Model Test Perplexity: {new_neural_test_perplexity}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
